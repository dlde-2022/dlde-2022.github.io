---
layout: project
urltitle:  "The Symbiosis of Deep Learning and Differential Equations (DLDE)"
title: "The Symbiosis of Deep Learning and Differential Equations (DLDE)"
categories: nips, neurips, vancouver, canada, workshop, differential equations, machine learning, dlde, 2021, neurips21
permalink: /
<!-- favicon: /static/img/embodiedqa/favicon.png -->
bibtex: true
paper: true
acknowledgements: ""
---

<br>
<div class="row">
  <div class="col-xs-12">
    <center><h1>The Symbiosis of Deep Learning and Differential Equations (DLDE) - II </h1></center>
    <center><h2>NeurIPS 2022 Workshop</h2></center>
    <center><span style="color:#e74c3c;font-weight:400;">
      December 14th, 08:00 AM to 16:00 PM EST,
      Virtual Workshop
    </span></center>
  </div>
</div>

<hr>

<div class="row" id="intro"> 
  <div class="col-md-12">
   <center>
    <img src="{{ "/static/img/banner/epic.png" | prepend:site.baseurl }}"> 
    </center>
    <p> </p> 
  </div> 
</div>


<br>
<div class="row" id="intro">
  <div class="col-xs-12">
    <h2>Introduction</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
<p>

<p>
In recent years, there has been a rapid increase of machine learning applications in computational sciences, with some of the most impressive results at the interface of deep learning (DL) and differential equations (DEs). 
DL techniques have been used in a variety of ways to dramatically enhance the effectiveness of DE solvers and computer simulations.
These successes have widespread implications, as DEs are among the most well-understood tools for the mathematical analysis of scientific knowledge, and they are fundamental building blocks for mathematical models in engineering, finance, and the natural sciences.
Conversely, DL algorithms based on DEs--such as neural differential equations and continuous-time diffusion models--have also been successfully employed as deep learning models.
Moreover, theoretical tools from DE analysis have been used to glean insights into the expressivity and training dynamics of mainstream deep learning algorithms. </p>

<p>
This workshop will aim to bring together researchers with backgrounds in computational science and deep learning to encourage intellectual exchanges, cultivate relationships and accelerate research in this area.
The scope of the workshop spans topics at the intersection of DL and DEs, including theory of DL and DEs, neural differential equations, solving DEs with neural networks, and more. </p>


<p>

</p>

<br>

<div class="row" id="dates">
  <div class="col-xs-12">
    <h2>Important Dates</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Submission Deadline (Extended)</td>
          <td>September 24th,  2022 - Anywhere on Earth (AoE)</td>
        </tr>
        <tr>
          <td>Final Decisions</td>
          <td>October 17th, 2022 - AoE </td>
        </tr>
        <tr>
          <td>Workshop Date</td>
          <td>December 14th, 2022 - AoE </td>
        </tr>
      </tbody>
    </table>
  </div>
</div><br>

<div class="row" id="cfp">
  <div class="col-xs-12">
    <h2>Call for Extended Abstracts</h2>
  </div>
</div>
<div class="row">
  <div class="col-xs-12">
    <p>
      We invite high-quality extended abstract submissions on the intersection of DEs and DL. Some examples (non-exhaustive list):
    </p>

<p>  
<div class="row">
  <div class="col-xs-12">
    <ul>
      <li>Using differential equation models to understand and improve deep learning algorithms: </li> 
      <ul>
        <li>Incorporating DEs into existing DL models (neural differential equations, diffusion models, ...)  </li> 
        <li>Analysis of numerical methods for implementing DEs in DL models (trade-offs, benchmarks, ...) </li> 
        <li>Modeling training dynamics using DEs to generate theoretical insights and novel algorithms. </li>
      </ul>
      <li>Using deep learning algorithms to create or solve differential equation models:</li> 
      <ul>
        <li>DL methods for solving high-dimensional, highly parameterized, or otherwise challenging DE models.</li>
        <li>Learning-augmented numerical methods for DEs (hypersolvers, hybrid solvers ...) </li>
        <li>Specialized DL architectures for solving DEs (neural operators, PINNs, ...). </li>
      </ul>
    </ul>
  </div>
</div>
</p>

  <p> <span style="font-weight:500;">Submission:</span>
  <br/>
    Accepted submissions will be presented during joint poster sessions and will be made publicly available as non-archival reports, allowing future submissions to archival conferences or journals. 
    Exceptional submissions will be either selected for four 15-minute contributed talks
    or eight 5-minute spotlight oral presentations. 
  </p>

  <p>
  Submissions should be up to 4 pages excluding references, acknowledgements, and supplementary material, and should be
      <span style="color:#3a92d6;font-weight:400;"><a href="https://github.com/dl-de/dl-de.github.io/blob/main/static/sty/dlde_neurips_2021.sty">DLDE-NeurIPS format</a></span> and anonymous. Long appendices are permitted but strongly discouraged, and reviewers are not required to read them. The review process is double-blind.
  </p>
  <p>
  We also welcome submissions of recently published work that is strongly within the scope of the workshop (with proper formatting). We encourage the authors of such submissions to focus on accessibility to the wider NeurIPS community while distilling their work into an extended abstract. Submission of this type will be eligible for poster sessions after a lighter review process.
  </p>
  <p>
  Authors may be asked to review other workshop submissions. 
  </p>
  <p>
  Please submit your extended abstract to <span style="color:#3a92d6;font-weight:400;"><a href="https://openreview.net/group?id=NeurIPS.cc/2021/Workshop/DLDE">this address.</a></span>
   </p>
    <p>
  If you have any questions, send an email to one of the following: [luca.celotti@usherbrooke.ca, poli@stanford.edu]
  </p>

  </div>

</div><br>



<div class="row" id="schedule">
  <div class="col-xs-12">
    <h2>Schedule</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <p><b>(EST) Morning </b></p>
    <ul>
      <li>06:45 : Introduction and opening remarks</li>
      <li>07:00 : Invited Talk 1</li>
      <li>07:45 : Spotlight Talk 1 </li>
      <li>08:00 : Spotlight Talk 2 </li>
      <li>08:15 : Invited Talk 2 </li>
      <li>09:00 : Coffee Break</li>
      <li>09:15 : Spotlight Talk 3 </li>
      <li>09:30 : Spotlight Talk 4 </li>
      <li>09:45 : Poster Session 1 </li>
      <li>10:30 : Invited Talk 3 </li>
      <li>11:15 : Lunch Break </li>
    </ul>
    <p><b>(EST) Afternoon </b></p>
    <ul>
      <li>13:45 : Spotlight Talk 5 </li>
      <li>14:00 : Spotlight Talk 6 </li>
      <li>14:15 : Coffee Break</li>
      <li>14:30 : Poster Session 2 </li>
      <li>15:15 : Invited Talk 4 </li>
      <li>16:00 : Spotlight Talk 7 </li>
      <li>16:15 : Spotlight Talk 8 </li>
    </ul>
  </div>
</div>



<br>
<div class="row" id="speakers">
  <div class="col-xs-12">
    <h2>Invited Speakers</h2>
  </div>
</div><br>


<div class="row">
  <div class="col-md-12">
    <img class="speaker-pic" style="float:left;margin-right:30px;" src="{{ "/static/img/people/chrisrackauckas.jpg" | prepend:site.baseurl }}">
    <p><b>Chris Rackauckas</b>
    (confirmed) is the Co-PI of the Julia Lab at the Computer Science and AI Laboratory (CSAIL) of the Massachussets Institute of Science and Technology (MIT), as well as the director of Modeling and Simulation at Julia Computing and of Scientific Research at Pumas-AI. His research spans topics in numerical methods for differential equations, scientific machine learning and high-performance computing. He is the lead developer of the DifferentialEquations.jl solver suite along with over a hundred other Julia packages, earning him the inaugural Julia Community Prize, an outstanding paper award at the IEEE-HPEC conference on computational derivation for the efficient stochastic differential equation solvers, and front page features on many tech community sites.
    <span style="color:#3a92d6;font-weight:400;">[<a href="https://chrisrackauckas.com/">Webpage</a>]</span></p>
  </div>
</div><br>


<div class="row">
  <div class="col-md-12">
    <img class="speaker-pic" style="float:left;margin-right:30px;" src="{{ "/static/img/people/philippgrohs.jpg" | prepend:site.baseurl }}">
    <p><b>Philipp Grohs</b>
    (confirmed) is a professor at the University of Vienna. His research interests lie in approximation theory and computational harmonic analysis. In addition, he is known for his work on numerical methods for PDEs, and has made important contributions to the development and analysis of machine learning algorithms for the numerical approximation of high-dimensional PDEs. Of particular notice is his theoretical work on error estimates for deep network approximations to the solutions of PDEs, including his proofs that neural networks overcome the curse of dimensionality in these applications.     
    <span style="color:#3a92d6;font-weight:400;">[<a href="https://mat.univie.ac.at/~grohs/">Webpage</a>]</span></p>
  </div>
</div><br>


<div class="row">
  <div class="col-md-12">
    <img class="speaker-pic" style="float:left;margin-right:30px;" src="{{ "/static/img/people/weinane.jpg" | prepend:site.baseurl }}">
    <p><b>Weinan E</b>
    (confirmed) is a professor in Applied and Computational Mathematics at Princeton University. His current research interests lie at the intersection of mathematics, physics, and machine learning. He has made important contributions to the theoretical foundations of deep neural networks, exploring questions on training dynamics and generalization. Additionally, he has driven the development of machine learning algorithms for use in computational science, including solution methods for complicated PDE problems and techniques for incorporating mathematical models into data-driven approaches. 
    <span style="color:#3a92d6;font-weight:400;">[<a href="https://web.math.princeton.edu/~weinan/">Webpage</a>]</span></p>
  </div>
</div><br>



<div class="row" id="recordings">
    <div class="col-xs-12">
    <h2>Recordings</h2>
  </div>
</div>

<div class="row">
  <div class="col-xs-12">
    <p>
    The workshop will be broadcasted via Zoom and poster sessions will be on Gathertown. We will upload the recordings on YouTube.</p>
  </div>
</div>

<div class="row" id="accepted_papers">
  <div class="col-xs-12">
    <h2>Accepted Papers</h2>
    <p><span style="color:#3a92d6;font-weight:400;"><a href="https://openreview.net/group?id=NeurIPS.cc/2021/Workshop/DLDE#accept--spotlight-">Spotlight papers</a></span></p>
    <p><span style="color:#3a92d6;font-weight:400;"><a href="https://openreview.net/group?id=NeurIPS.cc/2021/Workshop/DLDE#accept--poster-">Poster papers</a></span></p>
  </div>
</div>

<div class="row" id="organizers">
  <div class="col-xs-12">
    <h2>Organizers</h2>
  </div>
</div>

<div class="row">
  
   <div class="col-xs-3">
    <a href="https://www.ekbuchanan.com/">
      <img class="people-pic" src="{{ "/static/img/people/kellybuchanan.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.ekbuchanan.com/">Kelly Buchanan</a>
      <h6>Columbia University</h6>
    </div>
  </div>


  <div class="col-xs-3">
    <a href="https://animesh.garg.tech/">
      <img class="people-pic" src="{{ "/static/img/people/animeshgarg.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://animesh.garg.tech/">Animesh Garg</a>
      <h6>University of Toronto, Vector Institute, NVIDIA</h6>
    </div>
  </div>

  <div class="col-xs-3">
    <a href="https://lucehe.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/lucaherrtti.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://lucehe.github.io/">Luca Herranz-Celotti</a>
      <h6>Université de Sherbrooke</h6>
    </div>
  </div>

</div>

<div class="row">
  <div class="col-xs-3">
    <a href="http://thorjonsson.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/thor.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://thorjonsson.github.io/">Thor Jonsson</a>
      <h6>University of Guelph</h6>
    </div>
  </div>

  <div class="col-xs-3">
    <a href="https://kidger.site/">
      <img class="people-pic" src="{{ "/static/img/people/patrickkidger.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://kidger.site/">Patrick Kidger</a>
      <h6>University of Oxford</h6>
    </div>
  </div>

  <div class="col-xs-3">
    <a href="https://martinmagill.netlify.app/">
      <img class="people-pic" src="{{ "/static/img/people/martinmagill.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://martinmagill.netlify.app/">Martin Magill</a>
      <h6>Ontario Tech University</h6>
    </div>
  </div>


  <div class="col-xs-3">
    <a href="https://scholar.google.com/citations?user=IwCfl4UAAAAJ&hl=en">
      <img class="people-pic" src="{{ "/static/img/people/stefanomassaroli.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://scholar.google.com/citations?user=IwCfl4UAAAAJ&hl=en">Stefano Massaroli</a>
      <h6>University of Tokyo, RIKEN</h6>
    </div>
  </div>
  </div>

  <div class="row">

  <div class="col-xs-3">
    <a href="https://zymrael.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/michaelpoli2.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://zymrael.github.io/">Michael Poli</a>
      <h6>Stanford University</h6>
    </div>
  </div>

  <div class="col-xs-3">
    <a href="https://n3as.berkeley.edu/p/fellow/ermal-rrapaj/">
      <img class="people-pic" src="{{ "/static/img/people/ermalrrapaj.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://n3as.berkeley.edu/p/fellow/ermal-rrapaj/">Ermal Rrapaj</a>
      <h6>University of California, Berkley</h6>
    </div>
  </div>


  </div>

<hr>

<div class="row">
  <div class="col-xs-12">
    <h2>Attending the workshop</h2>
  </div>
</div>



There are two ways to attend the presentations on the day of the workshop.
The first option is to watch the presentations at this <a href="https://neurips.cc/virtual/2021/workshop/21880">link</a>. Please use the rocket.chat text interface on that page to submit questions for the presenters.
Alternatively, attendees can join the Zoom meeting directly using the link at the top of that page. As an attendee in the Zoom meeting, you will be able to raise your hand to ask questions directly with your microphone and camera.
We would like to encourage everyone to attend via the Zoom meeting whenever feasible. Our hope is that the workshop will be as interactive and engaging as possible for an online event.
Additional details about attending the NeurIPS 2021 virtual conference in general can be found 
<a href="https://neurips.cc/virtual/2021/index.html">here</a>.


<p>

</p>
<br>

<div class="row">
  <div class="col-xs-12">
    <h2>Poster sessions in GatherTown</h2>
  </div>
</div>


The poster sessions will be hosted by GatherTown at the following 
<a href="https://eventhosts.gather.town/wR7m2n0AMEhpzwM2/neurips2021reserveSpace8">link</a>
.
If you are logged into your NeurIPS account in your browser, GatherTown will try to detect these login credentials and automatically create a GatherTown profile based on your NeurIPS profile. If this isn’t happening, you can also follow the GatherTown instructions on how to create a profile when signing in for the first time.
For those who have not used GatherTown before, there is a quick tutorial available on the website when you log in. Alternatively, you can find resources on
 <a href="https://support.gather.town/help/gather-basics">their website</a>.

<p>

</p>

<br>

<div class="row">
  <div class="col-xs-12">
    <h2>Expert panel session</h2>
  </div>
</div>


We are pleased to be hosting an expert panel session at 11pm EST on “Solving Differential Equations with Deep Learning: State of the Art and Future Directions”. Our panelists are Profs. Anima Anandkumar, Weinan E, and Neha Yadav.
We would like to encourage the audience to participate actively with our panelists. If possible, please join this event through the Zoom meeting, so that questions can be posed using microphones and cameras. Of course, we will also be monitoring the rocket.chat interface.
Those who would like to submit questions for our panelists ahead of time can do so through the following <a href="https://forms.gle/j37v5zmck1k1psww6">form</a>.

<p>

</p>
<br>

<div class="row">
  <div class="col-xs-12">
    <h2>Acknowledgments</h2>
  </div>
</div>
<a name="/acknowledgements"></a>
<div class="row">
  <div class="col-xs-12">
    <p>
      Thanks to <span style="color:#3a92d6;font-weight:400;"> <a href="https://visualdialog.org/">visualdialog.org</a></span> for the webpage format. Thanks to <span style="color:#3a92d6;font-weight:400;"> <a href="https://whatsonmyblackboard.wordpress.com/2014/10/28/backward-differential-equations/">whatsonmyblackboard</a></span>
       for the cozy blackboard photo.
    </p>
  </div>
</div>



<div class="row">
  <div class="col-xs-12">
    <h2>References</h2>
  </div>
</div>
<div class="row">
    <a id="note1" href="#note1ref">[1]</a> M. Raissi, P. Perdikaris and G.E. Karniadakis
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://www.sciencedirect.com/science/article/pii/S0021999118307125">
    Physics-informed neural networks: A deep learning framework for solving forward and inverse problems 
    involving nonlinear partial differential equations.</a></span> 
    Journal of Computational Physics, 2019.

    <br><a id="note1" href="#note1ref">[2]</a> D. Kochkov,  J.A. Smith, A. Alieva, Q. Wang,  M.P. Brenner, and S. Hoyer 
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://www.pnas.org/content/118/21/e2101784118">
    Machine learning–accelerated computational fluid dynamics.</a></span> 
    PNAS, 2021.

    <br><a id="note1" href="#note2ref">[3]</a> E. Haber and L. Ruthotto 
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://iopscience.iop.org/article/10.1088/1361-6420/aa9a90/meta">
    Stable architectures for deep neural networks.</a></span> 
    IOPScience, 2017.

    <br><a id="note1" href="#note2ref">[4]</a> R.T.Q. Chen, Y. Rubanova, J. Bettencourt, D. Duvenaud
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://papers.nips.cc/paper/2018/file/69386f6bb1dfed68692a24c8686939b9-Paper.pdf">
    Neural Ordinary Differential Equations.</a></span> 
    NeurIPS, 2018.

    <br><a id="note1" href="#note3ref">[5]</a> G. Carleo, M. Troyer
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://science.sciencemag.org/content/355/6325/602">
    Solving the quantum many-body problem with artificial neural networks.</a></span> 
    Science, 2017.


    <br><a id="note1" href="#note4ref">[6]</a> P. Chaudhari, S. Soatto
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://openreview.net/forum?id=HyWrIgW0W">
    Stochastic gradient descent performs variational inference, converges to limit cycles for deep networks.</a></span> 
    ICLR, 2018.


    <br><a id="note1" href="#note4ref">[7]</a> Q. Li, C. Tai, W. E
    <span style="color:#3a92d6;font-weight:400;"> <a href="http://proceedings.mlr.press/v70/li17f.html">
    Stochastic Modified Equations and Adaptive Stochastic Gradient Algorithms.</a></span> 
    ICML, 2017.


    <br><a id="note1" href="#note5ref">[8]</a> W. E, C. Ma & L. Wu 
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://link.springer.com/article/10.1007/s00365-021-09549-y">
    The Barron Space and the Flow-Induced Function Spaces for Neural Network Models.</a></span> 
    Constructive Approximation, 2021.


    <br><a id="note1" href="#note6ref">[9]</a> Z. Li, N. Kovachki, K. Azizzadenesheli, B. Liu, K. Bhattacharya, A. Stuart, A. Anandkumar
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://openreview.net/pdf?id=c8P9NQVtmnO">
    Fourier Neural Operator for Parametric Partial Differential Equations.</a></span> 
    ICLR, 2021.


    <br><a id="note1" href="#note7ref">[10]</a> J. Sirignano, K. Spiliopoulos
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://www.sciencedirect.com/science/article/pii/S0021999118305527">
    DGM: A deep learning algorithm for solving partial differential equations.</a></span> 
    Journal of Computational Physics, 2018.

    <br><a id="note1" href="#note8ref">[11]</a> L. Lu, X. Meng, Z. Mao, G.E. Karniadakis
    <span style="color:#3a92d6;font-weight:400;"> <a href="https://epubs.siam.org/doi/pdf/10.1137/19M1274067">
    DeepXDE: A Deep Learning Library for Solving Differential Equations.</a></span> 
    Society for Industrial and Applied Mathematics, 2021.


    <br><a id="note1" href="#note9ref">[12]</a> S. Mishra, R. Molinaro
    <span style="color:#3a92d6;font-weight:400;"> 
    <a href="https://academic.oup.com/imajna/advance-article-abstract/doi/10.1093/imanum/drab032/6297946?redirectedFrom=fulltext">
    Estimates on the generalization error of physics-informed neural networks for approximating a class of inverse problems for PDEs.</a></span> 
    IMA Journal of Numerical Analysis, 2021.

    <br><a id="note1" href="#note10ref">[13]</a> S. Bai, J.Z. Kolter, V. Koltun
    <span style="color:#3a92d6;font-weight:400;"> 
    <a href="https://proceedings.neurips.cc/paper/2019/file/01386bd6d8e091c2ab4c7c7de644d37b-Paper.pdf">
    Deep Equilibrium Models.</a></span> 
    NeurIPS, 2019.


    <br><a id="note1" href="#note14ref">[14]</a> N. Yadav, K.S. McFall, M. Kumar, J.H. Kim
    <span style="color:#3a92d6;font-weight:400;"> 
    <a href="https://link.springer.com/article/10.1007/s00521-016-2722-9">
    A length factor artificial neural network method for the numerical solution of the advection dispersion equation characterizing the mass balance of fluid flow in a chemical reactor.</a></span> 
    Neural Computing and Applications, 2018.



    <br><a id="note1" href="#note15ref">[15]</a> C. Beck, S. Becker, P. Grohs, N. Jaafari, A. Jentzen 
    <span style="color:#3a92d6;font-weight:400;"> 
    <a href="https://link.springer.com/article/10.1007/s10915-021-01590-0">
    Solving the Kolmogorov PDE by Means of Deep Learning.</a></span> 
    Journal of Scientific Computing, 2021.


</div>

<br><br><br><br><br><br><br>



